{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "# torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyNet(nn.Module):\n",
    "    \"\"\"\n",
    "    多层感知机\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z1 = self.linear1(x)\n",
    "        a1 = self.relu1(z1)\n",
    "        y_pred = self.linear2(a1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11991, 300]) torch.Size([11991, 5])\n"
     ]
    }
   ],
   "source": [
    "def load_train_data(in_name):\n",
    "    \"\"\"\n",
    "    加载训练数据\n",
    "    \"\"\"\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for line in open(in_name):\n",
    "        label, vec = line.strip().split('\\t')\n",
    "        y_i = np.zeros(5)\n",
    "        y_i[int(label)] = 1\n",
    "        y_data.append(y_i)\n",
    "        x_data.append(np.array([float(v) for v in vec.split(',')]))\n",
    "    return x_data, y_data\n",
    "\n",
    "x_data, y_data = load_train_data('data/train/train_data_ACL-20180712.txt')\n",
    "x_data = torch.tensor(x_data, dtype=torch.float)\n",
    "y_data = torch.tensor(y_data, dtype=torch.float)\n",
    "print(x_data.size(), y_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 设置参数\n",
    "input_size, hidden_size, output_size = 300, 100, 5\n",
    "learning_rate = 1e-5\n",
    "EPOCH = 5000\n",
    "\n",
    "# 定义函数\n",
    "mod = MyNet(input_size, hidden_size, output_size)\n",
    "\n",
    "# 定义损失函数\n",
    "loss_fn = nn.MSELoss(size_average=False)\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.SGD(mod.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11615.4599609375\n",
      "8750.8349609375\n",
      "8617.62109375\n",
      "8526.04296875\n",
      "8466.537109375\n",
      "8412.2197265625\n",
      "8342.642578125\n",
      "8262.72265625\n",
      "8200.2548828125\n",
      "8079.6328125\n"
     ]
    }
   ],
   "source": [
    "## 开始训练 ##\n",
    "for t in range(EPOCH):\n",
    "    \n",
    "    # 向前传播\n",
    "    y_pred = mod(x_data)\n",
    "    \n",
    "    # 计算损失\n",
    "    loss = loss_fn(y_pred, y_data)\n",
    "    # 显示损失\n",
    "    if t % 500 == 0:\n",
    "        print(loss.data.item())\n",
    "    \n",
    "    # 在我们进行梯度更新之前，\n",
    "    # 先使用optimier对象提供的清除已经积累的梯度。\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 计算梯度\n",
    "    loss.backward()\n",
    "    \n",
    "    # 更新梯度\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
